{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tkgGE0urjQy",
        "outputId": "9ad55946-e748-49a3-8dca-067bb3fc47de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import bz2\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = bz2.BZ2File('train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('test.ft.txt.bz2')"
      ],
      "metadata": {
        "id": "xLFEqsDirmSO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_extract(file):\n",
        "    texts, labels = [], []\n",
        "    for line in file:\n",
        "        x = line.decode('utf-8')  # decode binary to string\n",
        "        labels.append(int(x[9]) - 1)  # extract labels\n",
        "        texts.append(x[10:].strip())  # extract texts\n",
        "    print('Done !')\n",
        "    return np.array(labels), texts"
      ],
      "metadata": {
        "id": "1ysUodV8r1tI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels, train_texts = load_extract(train_file)\n",
        "test_labels, test_texts = load_extract(test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA1Cz3HBr414",
        "outputId": "49a52010-9607-4464-bdd2-c96704324928"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done !\n",
            "Done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qKbmygBOsb1y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fu6K09JhzYz7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import bz2\n",
        "\n",
        "# Open the bz2 file\n",
        "with bz2.BZ2File('train.ft.txt.bz2', 'r') as f:\n",
        "    # Read the lines from the file\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Convert lines to strings\n",
        "lines = [line.decode('utf-8') for line in lines]\n",
        "\n",
        "# Split each line into label and text\n",
        "data = [line.split(' ', 1) for line in lines]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=['label', 'text'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Z7ch6Zuy5e",
        "outputId": "7d2e661b-c994-4af7-a297-2b0c563173b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        label                                               text\n",
            "0  __label__2  Stuning even for the non-gamer: This sound tra...\n",
            "1  __label__2  The best soundtrack ever to anything.: I'm rea...\n",
            "2  __label__2  Amazing!: This soundtrack is my favorite music...\n",
            "3  __label__2  Excellent Soundtrack: I truly like this soundt...\n",
            "4  __label__2  Remember, Pull Your Jaw Off The Floor After He...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "print(df.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-q5iBO6vZOv",
        "outputId": "dea60410-97f0-4849-b54b-f5e06295972b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              label                                               text\n",
            "3599995  __label__1  Don't do it!!: The high chair looks great when...\n",
            "3599996  __label__1  Looks nice, low functionality: I have used thi...\n",
            "3599997  __label__1  compact, but hard to clean: We have a small ho...\n",
            "3599998  __label__1  what is it saying?: not sure what this book is...\n",
            "3599999  __label__2  Makes My Blood Run Red-White-And-Blue: I agree...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_texts(texts):\n",
        "    stwords = stopwords.words('english')\n",
        "    temp_texts = []\n",
        "    for i in range(len(texts)):\n",
        "        text = re.sub('\\d','0',texts[i]) #replace every digit with 0\n",
        "        if 'www.' in text or 'http:' in text or 'https:' in text or '.com' in text: # remove links and urls\n",
        "            text = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \" \", text)\n",
        "\n",
        "        text = re.sub('[^a-zA-Z]', ' ', text) #anything which is not a character replace with whitespace char\n",
        "        text = text.lower()\n",
        "        text = text.split()\n",
        "        text = [word for word in text if not word in stwords] # remove stopwords\n",
        "        text = ' '.join(text)\n",
        "        temp_texts.append(text)\n",
        "    print('--100%--Done !')\n",
        "    return temp_texts"
      ],
      "metadata": {
        "id": "4Dh6b_dFuxRm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Processing Training data')\n",
        "train_texts = clean_texts(train_texts)\n",
        "print('\\nProcessing Test data')\n",
        "test_texts = clean_texts(test_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbYd6tpevooI",
        "outputId": "2cbb9efb-1548-4b6f-a3a1-00fff2fcd9d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Training data\n",
            "--100%--Done !\n",
            "\n",
            "Processing Test data\n",
            "--100%--Done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[0]"
      ],
      "metadata": {
        "id": "httfxJBuzas0",
        "outputId": "0ab6531e-aa5e-45f3-eb0d-455405b21557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stuning even non gamer sound track beautiful paints senery mind well would recomend even people hate vid game music played game chrono cross games ever played best music backs away crude keyboarding takes fresher step grate guitars soulful orchestras would impress anyone cares listen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-usc8RFsyQUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bz2\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "\n",
        "# Function to load and extract labels and texts from the file\n",
        "def load_extract(file, max_samples=None):\n",
        "    texts, labels = [], []\n",
        "    total_samples = 0\n",
        "    for line in file:\n",
        "        x = line.decode('utf-8')  # decode binary to string\n",
        "        labels.append(int(x[9]) - 1)  # extract labels\n",
        "        texts.append(x[10:].strip())  # extract texts\n",
        "        total_samples += 1\n",
        "        # Break loop if maximum number of samples is reached\n",
        "        if max_samples is not None and total_samples >= max_samples:\n",
        "            break\n",
        "    print('Done !')\n",
        "    return np.array(labels), texts\n",
        "\n",
        "# Function to clean texts\n",
        "def clean_texts(texts):\n",
        "    stwords = stopwords.words('english')\n",
        "    temp_texts = []\n",
        "    total_samples = len(texts)\n",
        "    for i, text in enumerate(texts):\n",
        "        text = re.sub('\\d','0',text) #replace every digit with 0\n",
        "        if 'www.' in text or 'http:' in text or 'https:' in text or '.com' in text: # remove links and urls\n",
        "            text = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \" \", text)\n",
        "\n",
        "        text = re.sub('[^a-zA-Z]', ' ', text) #anything which is not a character replace with whitespace char\n",
        "        text = text.lower()\n",
        "        text = text.split()\n",
        "        text = [word for word in text if not word in stwords] # remove stopwords\n",
        "        text = ' '.join(text)\n",
        "        temp_texts.append(text)\n",
        "        # Print progress every 10000 samples\n",
        "        if (i + 1) % 10000 == 0 or (i + 1) == total_samples:\n",
        "            print(f\"--{((i + 1) / total_samples) * 100:.2f}%--Done !\")\n",
        "    return temp_texts\n",
        "\n",
        "# Open the bz2 files and load data\n",
        "max_train_samples = 10000  # Set maximum number of train samples\n",
        "max_test_samples = 5000  # Set maximum number of test samples\n",
        "with bz2.BZ2File('train.ft.txt.bz2', 'r') as train_file, bz2.BZ2File('test.ft.txt.bz2', 'r') as test_file:\n",
        "    train_labels, train_texts = load_extract(train_file, max_samples=max_train_samples)\n",
        "    test_labels, test_texts = load_extract(test_file, max_samples=max_test_samples)\n",
        "\n",
        "# Cleaning the texts\n",
        "train_texts_cleaned = clean_texts(train_texts)\n",
        "test_texts_cleaned = clean_texts(test_texts)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQBu-zrWyPSV",
        "outputId": "493f473d-8915-40cf-baf5-3abccadf2876"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done !\n",
            "Done !\n",
            "--100.00%--Done !\n",
            "--100.00%--Done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "max_words = 10000  # Max number of words to keep\n",
        "maxlen = 100  # Max length of sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(train_texts_cleaned)\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_texts_cleaned), maxlen=maxlen)\n",
        "X_test = pad_sequences(tokenizer.texts_to_sequences(test_texts_cleaned), maxlen=maxlen)\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Model architecture\n",
        "embedding_dim = 100\n",
        "filters = 128\n",
        "kernel_size = 5\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(filters, kernel_size, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UZJWAOkzAvR",
        "outputId": "5136147e-4180-42a1-fa43-d0aaa0eefe4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 16s 48ms/step - loss: 0.5218 - accuracy: 0.7005 - val_loss: 0.3723 - val_accuracy: 0.8316\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 0.2328 - accuracy: 0.9112 - val_loss: 0.3718 - val_accuracy: 0.8370\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 15s 47ms/step - loss: 0.0952 - accuracy: 0.9672 - val_loss: 0.5159 - val_accuracy: 0.8238\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.0424 - accuracy: 0.9850 - val_loss: 0.9095 - val_accuracy: 0.8112\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 15s 48ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.7997 - val_accuracy: 0.8156\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.7997 - accuracy: 0.8156\n",
            "Test Accuracy: 0.8155999779701233\n"
          ]
        }
      ]
    }
  ]
}